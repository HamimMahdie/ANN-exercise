{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent and backpropagation\n",
    "\n",
    "- Part 2.1: With the same neural network from last week, understand how stochastic gradient descent is implemented.\n",
    "- Part 2.2: Do pen and paper calculations of backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T10:13:40.271320Z",
     "start_time": "2020-01-20T10:13:40.266929Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: Understanding SGD\n",
    "\n",
    "Let's reuse Michael Nielsen's neural network from last session. Some new question are inserted in the comments (they start with \"Q: \"). Michael uses [list comprehensions](https://www.w3schools.com/python/python_lists_comprehension.asp) a lot, so make sure to learn that syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T14:51:15.694576Z",
     "start_time": "2020-01-21T14:51:15.661650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def step(z, threshold=0.5):\n",
    "    if z > threshold:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# Feed forward neural network class\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        \n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, lr, test_data=None, silent=False):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        \n",
    "        n = len(training_data)\n",
    "        if test_data:\n",
    "            n_test = len(test_data)\n",
    "        \n",
    "        for j in range(epochs):\n",
    "            \n",
    "            # Q1: What happens here? Explain the contents of `mini_batches`.\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)\n",
    "            ]\n",
    "            \n",
    "            # Q2: And what does this step do?\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, lr)\n",
    "            \n",
    "            if not silent:\n",
    "                if test_data:\n",
    "                    print(\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data), n_test))\n",
    "                else:\n",
    "                    print(\"Epoch {0} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, lr):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``lr``\n",
    "        is the learning rate.\"\"\"\n",
    "        \n",
    "        # These two vectors correspond to -∇C(W) (and -∇C(b))\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # Q3: How does this code work to update `nabla_b` and `nabla_w`\n",
    "        for x, y in mini_batch:\n",
    "            nabla_b_i, nabla_w_i = self.backprop(x, y)\n",
    "            nabla_b = [nb+nb_i for nb, nb_i in zip(nabla_b, nabla_b_i)]\n",
    "            nabla_w = [nw+nw_i for nw, nw_i in zip(nabla_w, nabla_w_i)]\n",
    "            \n",
    "        # Q4: Now we have our gradient vectors, `nabla_b` and `nabla_w`. Explain how we use them\n",
    "        # to update the weights and biases\n",
    "        self.weights = [\n",
    "            w - lr * nw / len(mini_batch)\n",
    "            for w, nw in zip(self.weights, nabla_w)\n",
    "        ]\n",
    "        self.biases = [\n",
    "            b - lr * nb / len(mini_batch)\n",
    "            for b, nb in zip(self.biases, nabla_b)\n",
    "        ]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        # In backprop, we first do a feed forward step. We store all the\n",
    "        # intermediate values that get computed. This is because, when we\n",
    "        # compute the gradient on a weight, we ask how changing it a little\n",
    "        # might influence the value that gets computed with it. Hence we need\n",
    "        # to store these values.\n",
    "        \n",
    "        # Feedforward # \n",
    "        # ----------- #\n",
    "        \n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        \n",
    "        # Backward pass # \n",
    "        # ------------- #\n",
    "        \n",
    "        # Q5: What does the variable `delta` store here? Why is the last bias\n",
    "        # gradient exactly `delta`?\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        \n",
    "        # Q6: Seems like we are multiplying each of the outputs from the previous\n",
    "        # layer, with the delta. Can you explain why we do this? \n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book. Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on. It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        \n",
    "        # Q7: What does this loop do?\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "            \n",
    "        return nabla_b, nabla_w\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        if self.sizes[-1] == 1:\n",
    "            test_results = [\n",
    "                (step(self.feedforward(x)), y)\n",
    "                for x, y in test_data\n",
    "            ]\n",
    "        else:\n",
    "            test_results = [\n",
    "                (np.argmax(self.feedforward(x)), y)\n",
    "                for x, y in test_data\n",
    "            ]\n",
    "        return sum(int(y_pred == y) for (y_pred, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives dC_x/da\n",
    "        for the output activations.\"\"\"\n",
    "        return output_activations - y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.1.1** Draw a overview illustrating which method depend on which method in the `Network` class. Below, give a short explanation as to what each method does.\n",
    ">\n",
    "> *Hint*: You can draw by hand take a picture and put it into the notebook, work your paint skills, make ascii art or whatever your inner creative finds easiest. Just as long as one can somehow read the relations in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dependencies.png](dependencies.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.1.2** Answer questions Q1-4 in the code. Write / code down the answer to each one of them in cells below.\n",
    ">\n",
    "> *Hint*: You need to closely follow the code. You can verify that your idea of what a variable contains is correct, if you print it. Simply create an instance of the network and you will be able to access the variables of that instance to see what they look like. Example:\n",
    ">\n",
    ">     net = Network([2, 3, 1])\n",
    ">     net.biases  # this gets you the biases property of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "The purpose of shuffling the data points is to avoid falling into a false local minimums, breaking out of patterns, and reducing bias. We then build the batches that we will use for SGD using the list comprehension in the below line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2** \n",
    "\n",
    "For all of the mini batches that we initialized in the past step, we run the `self.update_mini_batch` function, which according to the function documentation:\n",
    "\n",
    "> *Update the network's weights and biases by applying gradient descent using backpropagation to a single mini batch. The ``mini_batch`` is a list of tuples ``(x, y)``, and ``lr`` is the learning rate.*\n",
    "\n",
    "this therefore is the step where we are applying the gradient descent on all of the batches that we were talking about.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "This code first excutes the function `self.backprop` to get an initial estimate of the gradient. According to the documentation for the function:\n",
    "\n",
    "> *Return a tuple ``(nabla_b, nabla_w)`` representing the gradient for the cost function C_x.  ``nabla_b`` and ``nabla_w`` are layer-by-layer lists of numpy arrays, similar to ``self.biases`` and ``self.weights``.*\n",
    "\n",
    "This will therefore calculate the gradients of the bias and weight matrix for this single batch, but we need to add this to the matrix for all of them, which is what we are doing with the lines\n",
    "\n",
    "``nabla_b = [nb+nb_i for nb, nb_i in zip(nabla_b, nabla_b_i)]``\n",
    "\n",
    "``nabla_w = [nw+nw_i for nw, nw_i in zip(nabla_w, nabla_w_i)]``\n",
    "\n",
    "which after running for all of the batches will give us something close to the true cost gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Let's look at the list comprehension:\n",
    ">self.weights = [\n",
    ">            w - lr * nw / len(mini_batch)\n",
    ">            for w, nw in zip(self.weights, nabla_w)]\n",
    "in the second line of this list comprehension, we zip together the true weights and the ones we predicted. We then in the first line assignment write over the weights using the following formula:\n",
    "\n",
    "$$w - \\frac{lr * nw}{|mini\\_batch|}$$\n",
    "\n",
    "by dividing by the size of the batch we calculate the average gradient. Here $lr$ represents the learning rate, $w$ represents the weight vector of the network, and $nw$ represents our temporary batch calculated weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1: Backpropagation\n",
    "\n",
    "**Your understanding** of neural networks should now be something along the lines of: (1) a datapoint propagates forward through the network, then (2) a cost (how bad the prediction is) is evaluated and its gradient wrt. each weight is computed, and finally (3) the weights are updated according to how much they influence the cost.\n",
    "\n",
    "However, something important is missing from our understanding at this point. Remember, that *gradient descent* – the algorithm for minimizing the cost function, which we can think of as ball rolling downhill – needs to known which direction is downhill on the cost function. The gradient tells us this. **So how do we compute the cost function's gradient?** Enter: *backpropagation*. Backpropagation is an algorithm which computes the gradient of the cost function wrt. each weight in the network, from end to start, by iteratively applying *the chain rule*. It is called *back*-propagation because it computes gradients from front to back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pen and paper calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, do some pen and paper calculations to hand-compute gradients in a real neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://raw.githubusercontent.com/abjer/tsds/master/material_exercises/week_3/2_3_1_net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.2.1**: The network above has a defined input and weights. If the true label for the datapoint `[4, 2]` is 1, what is the cost?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cost.png](cost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.2.2**: Knowing about backpropagation, we actually have everything we need to compute the gradients of the weights by hand. So go ahead and do that. Report your answer either as a diagram that includes the gradients (you can draw on my figure somehow and insert the resulting image), or just by writing what the gradient of each weight is.\n",
    ">\n",
    "> *Hint*: When computing gradients with backprop, it can be helpful to think of the network as a [computational graph](https://github.com/abjer/tsds/blob/master/material_exercises/week_3/2_3_1_net_compgraph.png?raw=true).\n",
    ">\n",
    "> *Hint*: Some of the gradients will become *very* small, known as the vanishing gradient problem. If they get smaller than 1e-4 you can just set them to zero.*\n",
    ">\n",
    "> *Note*: If you show me which equations you used and what your process is, I can give better feedback in case there are mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grad1.png](grad1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grad2.png](grad2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 2.2.3:** Provide answers to the code questions Q5-7.\n",
    ">\n",
    ">*Note:* `Q7` relies on having a solid grasp of the backpropagation equations (BP1-4) of Micheal Nielsens book. These cast what we learned today in vector notation, using matrix multiplication to compute the gradients of *vectors and matrices of weights*. You are not required to know these equations - the important thing is that you grasp the key ideas of backpropagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Q5: What does ⁠ delta ⁠ store? Why is the last bias gradient exactly ⁠ delta ⁠?*  \n",
    "The variable ⁠ delta ⁠ represents the error in the output layer, showing how much the network’s prediction differs from the expected result. It is calculated by taking the difference between the actual and predicted values and adjusting it using the slope of the activation function.  \n",
    "\n",
    "The last bias gradient is exactly ⁠ delta ⁠ because a bias is a direct addition to the neuron’s output. Since a bias does not depend on any inputs, its effect on the error is the same as the error itself. This makes the bias gradient equal to ⁠ delta ⁠ without any additional scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Q6: Why multiply previous layer outputs with ⁠ delta ⁠?*  \n",
    "The weight adjustments depend on both the error (⁠ delta ⁠) and the strength of the connection between neurons. The outputs of the previous layer determine how much influence each neuron had on the final prediction.  \n",
    "\n",
    "By multiplying ⁠ delta ⁠ with the activations from the previous layer, the network ensures that weights connected to highly active neurons are adjusted more, while those with little influence change less. This helps the network learn by updating the connections in proportion to their impact on the final decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Q7: What does this loop do?*  \n",
    "This loop moves backward through the network, layer by layer, updating the error at each step. It takes the error from one layer, adjusts it based on the connections to the next layer, and then calculates how much each neuron contributed to that error.  \n",
    "\n",
    "At each step, the biases are updated directly using the current error, while the weights are adjusted by considering both the error and the activations from the previous layer. This process ensures that every part of the network learns from the mistake and improves its contribution to the final prediction.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
